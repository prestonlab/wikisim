{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate embedding spaces based on MTurk data\n",
    "\n",
    "This notebook takes a CSV file with data from the MTurk study, parses it, and filters to get complete participants. It also scores the initial object test and the catch trials during the similarity judgments. Then it uses the PsiZ package to infer the psychological representation driving the similarity judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "module_path = os.path.abspath('..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from wikisim import simtask\n",
    "from wikisim import embed\n",
    "\n",
    "data_dir = '/Users/morton/Dropbox/data/bender'\n",
    "work_dir = '/Users/morton/Dropbox/work/bender/mturk'\n",
    "model_dir = '/Users/morton/Dropbox/work/bender/batch/models3'\n",
    "\n",
    "pool_file = os.path.join(data_dir, 'stimuli', 'stimuli.csv')\n",
    "tab_file = os.path.join(data_dir, 'mturk', 'data', 'Data_03.13.20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pool information and MTurk data\n",
    "\n",
    "MTurk data are downloaded from the experiment's data page. The pool information is stored in a CSV file that includes the name, category, and subcategory of each stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, pool = simtask.read_mturk(tab_file, pool_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize behavioral data\n",
    "\n",
    "Each participant only completes one condition. Conditions are:\n",
    "1. face semantic\n",
    "2. scene semantic\n",
    "3. face visual\n",
    "4. scene visual\n",
    "\n",
    "Tests and catch trials are scored and included in the summary:\n",
    "* familiarity: mean familiarity rating over all items (1: never heard of it; 4: know all about it)\n",
    "* test: fraction of object practice test trials answered correctly\n",
    "* catch: fraction of catch trials (i.e., similarity trials where one of the choices is a reversed version of the prompt item) answered correctly. A catch trial is scored as correct if the reversed image was either of the two responses\n",
    "* vis: post-experiment rating of how often visual similarity affected their judgments (1: 0-20%; 5: 80-100%)\n",
    "* sem: post-experiment rating of how often conceptual similarity affected their judgments\n",
    "\n",
    "The last five columns indicate the time in minutes that each phase took. The instruct column includes all instruction screens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary of participants who finished\n",
    "pd.set_option('display.max_rows', None)\n",
    "summary_raw = simtask.session_summary(data)\n",
    "summary = summary_raw.dropna().copy()\n",
    "\n",
    "# include only participants with reasonable performance\n",
    "completed = summary.query('age >= 22 and age <= 34').index\n",
    "include = summary.query('test > .6 and catch > .5 and age >= 22 and age <= 34').index\n",
    "summary.loc[:, 'include'] = 0\n",
    "summary.loc[include, 'include'] = 1\n",
    "\n",
    "summary = summary.sort_values(by=['condition', 'start_time'])\n",
    "summary.loc[completed].to_csv(os.path.join(work_dir, 'mturk_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Participants included: 102 / 151'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Participants included: {summary.include.sum()} / {summary.shape[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "1    26\n",
       "2    25\n",
       "3    25\n",
       "4    26\n",
       "Name: start_time, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get participants with reasonable performance\n",
    "included = summary.query('include == 1')\n",
    "included.groupby('condition')['start_time'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_include = data['fam']['subject'].isin(included.index)\n",
    "fam = data['fam'].loc[fam_include]\n",
    "fam.to_csv(os.path.join(work_dir, 'mturk_fam.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics\n",
    "\n",
    "Participants were screened to be self-reported as native English speakers and of age 22-34 (this is age range used in the original study, aged up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dem'].reindex(index=completed).to_csv(\n",
    "    os.path.join(work_dir, 'mturk_dem_completed.csv'))\n",
    "\n",
    "dem = data['dem'].reindex(index=included.index)\n",
    "dem.to_csv(os.path.join(work_dir, 'mturk_dem_included.csv'))\n",
    "dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=150\n",
      "Male      82\n",
      "Female    67\n",
      "Other      1\n",
      "Name: gender, dtype: int64\n",
      "mean    29.293333\n",
      "std      3.324803\n",
      "min     22.000000\n",
      "max     34.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# complete participants\n",
    "complete = data['dem'].reindex(index=completed)\n",
    "print(f'n={complete.shape[0]}')\n",
    "print(complete['gender'].value_counts())\n",
    "print(complete['age'].agg(['mean', 'std', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=102\n",
      "Male      57\n",
      "Female    44\n",
      "Other      1\n",
      "Name: gender, dtype: int64\n",
      "mean    29.392157\n",
      "std      3.285603\n",
      "min     22.000000\n",
      "max     34.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# included participants\n",
    "print(f'n={dem.shape[0]}')\n",
    "print(dem['gender'].value_counts())\n",
    "print(dem['age'].agg(['mean', 'std', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-experiment questionnaire\n",
    "\n",
    "Full answers to all questions. The \"clear\" column has a rating of how frequently (1-5) there was a clear answer on the similarity judgment trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "deb = data['deb'].reindex(index=included.index)\n",
    "deb = pd.concat((included.start_time, deb), axis=1).copy()\n",
    "deb = deb.sort_values(by=['condition', 'start_time'])\n",
    "deb.to_csv(os.path.join(work_dir, 'mturk_debrief.csv'))\n",
    "deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate embedding for each condition\n",
    "\n",
    "We estimate a separate embedding for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save similarity judgment data for included participants\n",
    "sim = data['sim'].loc[np.isin(data['sim'].subject, included.index)]\n",
    "\n",
    "# exclude catch trials\n",
    "sim = sim.loc[sim.trial_type == 'similarity']\n",
    "sim_file = os.path.join(work_dir, 'mturk_sim.csv')\n",
    "sim.to_csv(sim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     19.000000\n",
       "max     80.000000\n",
       "mean    72.686275\n",
       "std     11.034581\n",
       "Name: include, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.loc[:, 'include'] = sim['stim_fam'] > 1\n",
    "sim.groupby(['condition', 'subject'])['include'].sum().agg(['min', 'max', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "1    1999.0\n",
       "2    1783.0\n",
       "3    1824.0\n",
       "4    1808.0\n",
       "Name: include, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby('condition')['include'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/psiz/models.py:1227: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Progress: |██████████████████████████████████████████████████| 100.0%% Complete | ETA: 0:00:00\n",
      "    Elapsed time: 0:02:19\n",
      "    Progress: |--------------------------------------------------| 0.0%% Complete | ETA: 0:00:00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Progress: |██████████████████████████████████████████████████| 100.0%% Complete | ETA: 0:00:00\n",
      "    Elapsed time: 0:03:42\n",
      "    Progress: |--------------------------------------------------| 0.0%% Complete | ETA: 0:00:00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Progress: |██████████████████████████████████████████████████| 100.0%% Complete | ETA: 0:00:00\n",
      "    Elapsed time: 0:02:05\n",
      "    Progress: |--------------------------------------------------| 0.0%% Complete | ETA: 0:00:00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morton/miniconda3/envs/wikisim/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Progress: |██████████████████████████████████████████████████| 100.0%% Complete | ETA: 0:00:00\n",
      "    Elapsed time: 0:02:16\n"
     ]
    }
   ],
   "source": [
    "emb = embed.cond_embed(sim, pool, n_dim=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save embedding models for further analysis\n",
    "\n",
    "The embedding models are not transferable across categories. However, for ease of use given that each of the other models apply across category, saving them to a single file for each task condition. The two models are called SEM (semantic encoding model) and VEM (visual encoding model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.save_embed_rdm(model_dir, 'sem', emb, [1, 2], pool['stim'].tolist())\n",
    "embed.save_embed_rdm(model_dir, 'vem', emb, [3, 4], pool['stim'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond, e in emb.items():\n",
    "    embed_file = os.path.join(work_dir, f'mturk_embed_cond{cond}.hdf5')\n",
    "    e.save(embed_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikisim2",
   "language": "python",
   "name": "wikisim2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}